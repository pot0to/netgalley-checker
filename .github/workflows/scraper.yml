name: Daily NetGalley Scraper

on:
  schedule:
    # Run every day at 2 AM UTC (adjust to your timezone)
    - cron: '0 2 * * *'
  # Allow manual trigger from GitHub Actions tab
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    # This block gives the GitHub Actions bot permission to push code back to your repo
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright tabulate
          playwright install chromium
          # This installs the system libraries needed for Chromium to run in Linux
          playwright install-deps

      - name: Run scraper
        # We use xvfb-run to provide a virtual display since headless=False is likely in your code
        run: xvfb-run python netgalley-checker.py

      - name: Commit and push results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add netgalley_data.tsv
          git commit -m "Update: Daily scraper results - $(date)" || echo "No changes to commit"
          git push